{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "weather = pd.read_csv('data/weather.csv')\n",
    "pallet_history = pd.read_csv('data/Pallet_history_Gold_Spike.csv')\n",
    "inbound = pd.read_csv('data/inbound_loads.csv')\n",
    "outbound = pd.read_csv('data/outbound_laods.csv')\n",
    "demand = pd.read_csv('data/demand_kWtrain_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " #####\n",
      "Inbound: \n",
      " ##### \n",
      "\n",
      "Index(['front_temperature', 'middle_temperature', 'back_temperature',\n",
      "       'net_weight', 'case_quantity', 'pallet_count', 'truck_signin_datetime',\n",
      "       'load_time', 'truck_time'],\n",
      "      dtype='object')\n",
      "With NaN: (56146, 9)\n",
      "Without NaN: (8761, 9)\n",
      "\n",
      " #####\n",
      "Outbound: \n",
      " ##### \n",
      "\n",
      "Index(['net_weight', 'case_quantity', 'pallet_count', 'truck_signin_datetime',\n",
      "       'load_time', 'truck_time'],\n",
      "      dtype='object')\n",
      "With NaN: (112363, 6)\n",
      "Without NaN: (96704, 6)\n",
      "\n",
      " #####\n",
      "Demand:  \n",
      " ##### \n",
      "\n",
      "Full dataset: (365349, 3)\n",
      "Answers known until index:  273987\n",
      "Training set, 70%: (191789, 3)\n",
      "Validation set, 30%: (82197, 3)\n",
      "\n",
      " #####\n",
      "Weather:  \n",
      " ##### \n",
      "\n",
      "   Unnamed: 0  Relative Humidity  Temperature  hour    datetime_america\n",
      "0           0              50.37         53.6    18 2018-12-31 18:00:00\n",
      "1           1              50.37         53.6    18 2018-12-31 18:05:00\n",
      "2           2              50.37         53.6    18 2018-12-31 18:10:00\n",
      "3           3              50.37         53.6    18 2018-12-31 18:15:00\n",
      "4           4              50.37         53.6    18 2018-12-31 18:20:00\n",
      "Index(['Unnamed: 0', 'Relative Humidity', 'Temperature', 'hour',\n",
      "       'datetime_america'],\n",
      "      dtype='object')\n",
      "(328242, 5)\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "# Preprocess inbound csv:\n",
    "#################\n",
    "print('\\n #####\\nInbound: \\n ##### \\n')\n",
    "inbound_post = inbound[inbound.carrier_code != 'CANCEL']\n",
    "inbound_post = inbound[inbound.carrier_code != '']\n",
    "\n",
    "inbound_post['truck_signin_datetime'] = pd.to_datetime(inbound_post['truck_signin_datetime'])\n",
    "\n",
    "# Compute delta times\n",
    "inbound_load_time = pd.to_datetime(inbound_post['load_finish_datetime']) - pd.to_datetime(inbound_post['load_start_datetime'])\n",
    "inbound_truck_time = pd.to_datetime(inbound_post['truck_signin_datetime']) - pd.to_datetime(inbound_post['signout_datetime'])\n",
    "\n",
    "# Drop unnecessary columns\n",
    "inbound_post = inbound_post.drop(['Unnamed: 0', 'warehouse_order_number', 'customer_code', 'load_reference_number', 'carrier_code', 'weight_uom', 'load_finish_datetime', 'load_start_datetime', 'dock_door_number', 'trailer_number', 'signout_datetime'], axis=1)\n",
    "\n",
    "# Add time deltas\n",
    "inbound_post['load_time'] = inbound_load_time\n",
    "inbound_post['truck_time'] = inbound_truck_time\n",
    "\n",
    "print(inbound_post.columns)\n",
    "\n",
    "inbound_post['load_time'] = inbound_post['load_time'].dt.seconds\n",
    "inbound_post['truck_time'] = inbound_post['truck_time'].dt.seconds\n",
    "\n",
    "print('With NaN:', inbound_post.shape)\n",
    "\n",
    "# Drop rows with >0 NaN values\n",
    "inbound_post_nan = inbound_post.dropna().reset_index(drop=True)\n",
    "\n",
    "print('Without NaN:', inbound_post_nan.shape)\n",
    "\n",
    "#################\n",
    "# Preprocess outbound csv:\n",
    "#################\n",
    "print('\\n #####\\nOutbound: \\n ##### \\n')\n",
    "outbound_post = outbound[outbound.carrier_code != 'CANCEL']\n",
    "outbound_post = outbound[outbound.carrier_code != 'VOID']\n",
    "outbound_post = outbound[outbound.carrier_code != '']\n",
    "\n",
    "outbound_post['truck_signin_datetime'] = pd.to_datetime(outbound_post['truck_signin_datetime'])\n",
    "\n",
    "# Compute delta times\n",
    "outbound_load_time = pd.to_datetime(outbound_post['load_finish_datetime']) - pd.to_datetime(outbound_post['load_start_datetime'])\n",
    "outbound_truck_time = pd.to_datetime(outbound_post['truck_signin_datetime']) - pd.to_datetime(outbound_post['signout_datetime'])\n",
    "\n",
    "# Drop unnecessary columns\n",
    "outbound_post = outbound_post.drop(['Unnamed: 0', 'warehouse_order_number', 'customer_code', 'load_reference_number', 'carrier_code', 'weight_uom', 'load_finish_datetime', 'load_start_datetime', 'dock_door_number', 'trailer_number', 'signout_datetime'], axis=1)\n",
    "\n",
    "# Add time deltas\n",
    "outbound_post['load_time'] = outbound_load_time\n",
    "outbound_post['truck_time'] = outbound_truck_time\n",
    "\n",
    "print(outbound_post.columns)\n",
    "\n",
    "outbound_post['load_time'] = outbound_post['load_time'].dt.seconds\n",
    "outbound_post['truck_time'] = outbound_post['truck_time'].dt.seconds\n",
    "\n",
    "print('With NaN:', outbound_post.shape)\n",
    "\n",
    "# Drop rows with >0 NaN values\n",
    "outbound_post_nan = outbound_post.dropna().reset_index(drop=True)\n",
    "\n",
    "print('Without NaN:', outbound_post_nan.shape)\n",
    "\n",
    "#################\n",
    "# Preprocess demand csv:\n",
    "#################\n",
    "print('\\n #####\\nDemand:  \\n ##### \\n')\n",
    "\n",
    "demand['datetime_local'] = pd.to_datetime(demand['datetime_local'])\n",
    "\n",
    "end_known_idx = demand[demand.demand_kW > 1].index[-1]\n",
    "train_val_split = 0.7 # 70% train, 30% val\n",
    "end_train_idx = int((train_val_split) * end_known_idx)\n",
    "demand_train = demand[0:end_train_idx-1]\n",
    "demand_val = demand[end_train_idx:end_known_idx]\n",
    "\n",
    "print('Full dataset:', demand.shape)\n",
    "print('Answers known until index: ', end_known_idx)\n",
    "print(f'Training set, {int(train_val_split*100)}%:', demand_train.shape)\n",
    "print(f'Validation set, {int(100-train_val_split*100)}%:', demand_val.shape)\n",
    "\n",
    "#################\n",
    "# Preprocess weather csv:\n",
    "#################\n",
    "print('\\n #####\\nWeather:  \\n ##### \\n')\n",
    "\n",
    "weather_post = weather.copy()\n",
    "UTC6 = pd.to_datetime(weather_post['datetime_UTC']) - pd.Timedelta(hours=6)\n",
    "weather_post['datetime_america'] = UTC6\n",
    "weather_post = weather_post.drop('datetime_UTC', axis=1)\n",
    "weather_post = weather_post.drop('datetime', axis=1)\n",
    "\n",
    "print(weather_post.head())\n",
    "print(weather_post.columns)\n",
    "print(weather_post.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge inbound with demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inbound_post_nan.sort_values(\"truck_signin_datetime\", inplace=True)\n",
    "demand_inbound_merge = pd.merge_asof(demand_train, inbound_post_nan, left_on='datetime_local', right_on='truck_signin_datetime', direction='nearest')\n",
    "\n",
    "demand_inbound_merge_numerical = demand_inbound_merge.copy()\n",
    "demand_inbound_merge_numerical['datetime_local'] = demand_inbound_merge_numerical['datetime_local'].apply(lambda x: time.mktime(x.timetuple()))\n",
    "demand_inbound_merge_numerical['truck_signin_datetime'] = demand_inbound_merge_numerical['truck_signin_datetime'].apply(lambda x: time.mktime(x.timetuple()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge with outbound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "outbound_post_nan.sort_values(\"truck_signin_datetime\", inplace=True)\n",
    "outbound_merge = pd.merge_asof(demand_inbound_merge, outbound_post_nan, left_on='datetime_local', right_on='truck_signin_datetime', direction='nearest', suffixes=('_inbound', '_outbound'))\n",
    "\n",
    "outbound_merge_numerical = outbound_merge.copy()\n",
    "outbound_merge_numerical['datetime_local'] = outbound_merge_numerical['datetime_local'].apply(lambda x: time.mktime(x.timetuple()))\n",
    "outbound_merge_numerical['truck_signin_datetime_inbound'] = outbound_merge_numerical['truck_signin_datetime_inbound'].apply(lambda x: time.mktime(x.timetuple()))\n",
    "outbound_merge_numerical['truck_signin_datetime_outbound'] = outbound_merge_numerical['truck_signin_datetime_outbound'].apply(lambda x: time.mktime(x.timetuple()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge with weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_post.sort_values(\"datetime_america\", inplace=True)\n",
    "weather_merge = pd.merge_asof(outbound_merge, weather_post, left_on='datetime_local', right_on='datetime_america', direction='nearest')\n",
    "\n",
    "weather_merge_numerical = weather_merge.copy()\n",
    "weather_merge_numerical['datetime_local'] = weather_merge_numerical['datetime_local'].apply(lambda x: time.mktime(x.timetuple()))\n",
    "weather_merge_numerical['truck_signin_datetime_inbound'] = weather_merge_numerical['truck_signin_datetime_inbound'].apply(lambda x: time.mktime(x.timetuple()))\n",
    "weather_merge_numerical['truck_signin_datetime_outbound'] = weather_merge_numerical['truck_signin_datetime_outbound'].apply(lambda x: time.mktime(x.timetuple()))\n",
    "weather_merge_numerical['datetime_america'] = weather_merge_numerical['datetime_america'].apply(lambda x: time.mktime(x.timetuple()))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the date columns, because their magnitude may be interfering with the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_dates_merged = weather_merge_numerical.drop(['datetime_local', 'truck_signin_datetime_inbound', 'truck_signin_datetime_outbound', 'datetime_america'], axis=1)\n",
    "nonan_train = no_dates_merged.dropna().reset_index(drop=True)\n",
    "\n",
    "nonan_train.to_csv('preprocessed_data/preprocessed_train_data.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inbound_post_nan.sort_values(\"truck_signin_datetime\", inplace=True)\n",
    "demand_inbound_merge = pd.merge_asof(demand_val, inbound_post_nan, left_on='datetime_local', right_on='truck_signin_datetime', direction='nearest')\n",
    "\n",
    "demand_inbound_merge_numerical = demand_inbound_merge.copy()\n",
    "demand_inbound_merge_numerical['datetime_local'] = demand_inbound_merge_numerical['datetime_local'].apply(lambda x: time.mktime(x.timetuple()))\n",
    "demand_inbound_merge_numerical['truck_signin_datetime'] = demand_inbound_merge_numerical['truck_signin_datetime'].apply(lambda x: time.mktime(x.timetuple()))\n",
    "\n",
    "outbound_post_nan.sort_values(\"truck_signin_datetime\", inplace=True)\n",
    "outbound_merge = pd.merge_asof(demand_inbound_merge, outbound_post_nan, left_on='datetime_local', right_on='truck_signin_datetime', direction='nearest', suffixes=('_inbound', '_outbound'))\n",
    "\n",
    "outbound_merge_numerical = outbound_merge.copy()\n",
    "outbound_merge_numerical['datetime_local'] = outbound_merge_numerical['datetime_local'].apply(lambda x: time.mktime(x.timetuple()))\n",
    "outbound_merge_numerical['truck_signin_datetime_inbound'] = outbound_merge_numerical['truck_signin_datetime_inbound'].apply(lambda x: time.mktime(x.timetuple()))\n",
    "outbound_merge_numerical['truck_signin_datetime_outbound'] = outbound_merge_numerical['truck_signin_datetime_outbound'].apply(lambda x: time.mktime(x.timetuple()))\n",
    "\n",
    "weather_post.sort_values(\"datetime_america\", inplace=True)\n",
    "weather_merge = pd.merge_asof(outbound_merge, weather_post, left_on='datetime_local', right_on='datetime_america', direction='nearest')\n",
    "\n",
    "weather_merge_numerical = weather_merge.copy()\n",
    "weather_merge_numerical['datetime_local'] = weather_merge_numerical['datetime_local'].apply(lambda x: time.mktime(x.timetuple()))\n",
    "weather_merge_numerical['truck_signin_datetime_inbound'] = weather_merge_numerical['truck_signin_datetime_inbound'].apply(lambda x: time.mktime(x.timetuple()))\n",
    "weather_merge_numerical['truck_signin_datetime_outbound'] = weather_merge_numerical['truck_signin_datetime_outbound'].apply(lambda x: time.mktime(x.timetuple()))\n",
    "weather_merge_numerical['datetime_america'] = weather_merge_numerical['datetime_america'].apply(lambda x: time.mktime(x.timetuple()))\n",
    "\n",
    "no_dates_merged = weather_merge_numerical.drop(['datetime_local', 'truck_signin_datetime_inbound', 'truck_signin_datetime_outbound', 'datetime_america'], axis=1)\n",
    "nonan_val = no_dates_merged.dropna().reset_index(drop=True)\n",
    "\n",
    "nonan_val.to_csv('preprocessed_data/preprocessed_val_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (190966, 19)\n",
      "Validation set: (82192, 19)\n"
     ]
    }
   ],
   "source": [
    "print(f'Train set: {nonan_train.shape}')\n",
    "print(f'Validation set: {nonan_val.shape}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
