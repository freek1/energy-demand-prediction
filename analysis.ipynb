{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "e0ark8SXuFPw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "import time\n",
        "\n",
        "weather = pd.read_csv('data/weather.csv')\n",
        "pallet_history = pd.read_csv('data/Pallet_history_Gold_Spike.csv')\n",
        "inbound = pd.read_csv('data/inbound_loads.csv')\n",
        "outbound = pd.read_csv('data/outbound_laods.csv')\n",
        "demand = pd.read_csv('data/demand_kWtrain_val.csv')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocessing the csv files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " #####\n",
            "Inbound: \n",
            " ##### \n",
            "\n",
            "Index(['front_temperature', 'middle_temperature', 'back_temperature',\n",
            "       'net_weight', 'case_quantity', 'pallet_count', 'truck_signin_datetime',\n",
            "       'load_time', 'truck_time'],\n",
            "      dtype='object')\n",
            "With NaN: (56146, 9)\n",
            "Without NaN: (8761, 9)\n",
            "\n",
            " #####\n",
            "Outbound: \n",
            " ##### \n",
            "\n",
            "Index(['net_weight', 'case_quantity', 'pallet_count', 'truck_signin_datetime',\n",
            "       'load_time', 'truck_time'],\n",
            "      dtype='object')\n",
            "With NaN: (112363, 6)\n",
            "Without NaN: (96704, 6)\n",
            "\n",
            " #####\n",
            "Demand:  \n",
            " ##### \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\freek\\AppData\\Local\\Temp\\ipykernel_8244\\1462457516.py:71: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  demand['datetime_local'] = pd.to_datetime(demand['datetime_local'])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Full dataset: (365349, 3)\n",
            "Answers known until index:  273987\n",
            "Training set, 70%: (191789, 3)\n",
            "Validation set, 30%: (82197, 3)\n",
            "\n",
            " #####\n",
            "Weather:  \n",
            " ##### \n",
            "\n",
            "Index(['Unnamed: 0', 'datetime', 'Relative Humidity', 'Temperature', 'hour'], dtype='object')\n",
            "(328242, 5)\n"
          ]
        }
      ],
      "source": [
        "#################\n",
        "# Preprocess inbound csv:\n",
        "#################\n",
        "print('\\n #####\\nInbound: \\n ##### \\n')\n",
        "inbound_post = inbound[inbound.carrier_code != 'CANCEL']\n",
        "inbound_post = inbound[inbound.carrier_code != '']\n",
        "\n",
        "inbound_post['truck_signin_datetime'] = pd.to_datetime(inbound_post['truck_signin_datetime'])\n",
        "\n",
        "# Compute delta times\n",
        "inbound_load_time = pd.to_datetime(inbound_post['load_finish_datetime']) - pd.to_datetime(inbound_post['load_start_datetime'])\n",
        "inbound_truck_time = pd.to_datetime(inbound_post['truck_signin_datetime']) - pd.to_datetime(inbound_post['signout_datetime'])\n",
        "\n",
        "# Drop unnecessary columns\n",
        "inbound_post = inbound_post.drop(['Unnamed: 0', 'warehouse_order_number', 'customer_code', 'load_reference_number', 'carrier_code', 'weight_uom', 'load_finish_datetime', 'load_start_datetime', 'dock_door_number', 'trailer_number', 'signout_datetime'], axis=1)\n",
        "\n",
        "# Add time deltas\n",
        "inbound_post['load_time'] = inbound_load_time\n",
        "inbound_post['truck_time'] = inbound_truck_time\n",
        "\n",
        "print(inbound_post.columns)\n",
        "\n",
        "inbound_post['load_time'] = inbound_post['load_time'].dt.seconds\n",
        "inbound_post['truck_time'] = inbound_post['truck_time'].dt.seconds\n",
        "\n",
        "print('With NaN:', inbound_post.shape)\n",
        "\n",
        "# Drop rows with >0 NaN values\n",
        "inbound_post_nan = inbound_post.dropna().reset_index(drop=True)\n",
        "\n",
        "print('Without NaN:', inbound_post_nan.shape)\n",
        "\n",
        "#################\n",
        "# Preprocess outbound csv:\n",
        "#################\n",
        "print('\\n #####\\nOutbound: \\n ##### \\n')\n",
        "outbound_post = outbound[outbound.carrier_code != 'CANCEL']\n",
        "outbound_post = outbound[outbound.carrier_code != 'VOID']\n",
        "outbound_post = outbound[outbound.carrier_code != '']\n",
        "\n",
        "outbound_post['truck_signin_datetime'] = pd.to_datetime(outbound_post['truck_signin_datetime'])\n",
        "\n",
        "# Compute delta times\n",
        "outbound_load_time = pd.to_datetime(outbound_post['load_finish_datetime']) - pd.to_datetime(outbound_post['load_start_datetime'])\n",
        "outbound_truck_time = pd.to_datetime(outbound_post['truck_signin_datetime']) - pd.to_datetime(outbound_post['signout_datetime'])\n",
        "\n",
        "# Drop unnecessary columns\n",
        "outbound_post = outbound_post.drop(['Unnamed: 0', 'warehouse_order_number', 'customer_code', 'load_reference_number', 'carrier_code', 'weight_uom', 'load_finish_datetime', 'load_start_datetime', 'dock_door_number', 'trailer_number', 'signout_datetime'], axis=1)\n",
        "\n",
        "# Add time deltas\n",
        "outbound_post['load_time'] = outbound_load_time\n",
        "outbound_post['truck_time'] = outbound_truck_time\n",
        "\n",
        "print(outbound_post.columns)\n",
        "\n",
        "outbound_post['load_time'] = outbound_post['load_time'].dt.seconds\n",
        "outbound_post['truck_time'] = outbound_post['truck_time'].dt.seconds\n",
        "\n",
        "print('With NaN:', outbound_post.shape)\n",
        "\n",
        "# Drop rows with >0 NaN values\n",
        "outbound_post_nan = outbound_post.dropna().reset_index(drop=True)\n",
        "\n",
        "print('Without NaN:', outbound_post_nan.shape)\n",
        "\n",
        "#################\n",
        "# Preprocess demand csv:\n",
        "#################\n",
        "print('\\n #####\\nDemand:  \\n ##### \\n')\n",
        "\n",
        "demand['datetime_local'] = pd.to_datetime(demand['datetime_local'])\n",
        "\n",
        "end_known_idx = demand[demand.demand_kW > 1].index[-1]\n",
        "train_val_split = 0.7 # 70% train, 30% val\n",
        "end_train_idx = int((train_val_split) * end_known_idx)\n",
        "demand_train = demand[0:end_train_idx-1]\n",
        "demand_val = demand[end_train_idx:end_known_idx]\n",
        "\n",
        "print('Full dataset:', demand.shape)\n",
        "print('Answers known until index: ', end_known_idx)\n",
        "print(f'Training set, {int(train_val_split*100)}%:', demand_train.shape)\n",
        "print(f'Validation set, {int(100-train_val_split*100)}%:', demand_val.shape)\n",
        "\n",
        "#################\n",
        "# Preprocess weather csv:\n",
        "#################\n",
        "print('\\n #####\\nWeather:  \\n ##### \\n')\n",
        "\n",
        "weather_post = weather.drop('datetime_UTC', axis=1)\n",
        "weather_post['datetime'] = pd.to_datetime(weather_post['datetime'])\n",
        "\n",
        "print(weather_post.columns)\n",
        "print(weather_post.shape)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Merging inbound with demand"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        Unnamed: 0  datetime_local  demand_kW  front_temperature   \n",
            "191784      191784    1.628928e+09   2561.692               41.0  \\\n",
            "191785      191785    1.628928e+09   2864.648               41.0   \n",
            "191786      191786    1.628928e+09   2820.785               41.0   \n",
            "191787      191787    1.628928e+09   2817.942               41.0   \n",
            "191788      191788    1.628928e+09   2699.152               41.0   \n",
            "\n",
            "        middle_temperature  back_temperature  net_weight  case_quantity   \n",
            "191784                42.0              42.0     41198.0         1642.0  \\\n",
            "191785                42.0              42.0     41198.0         1642.0   \n",
            "191786                42.0              42.0     41198.0         1642.0   \n",
            "191787                42.0              42.0     41198.0         1642.0   \n",
            "191788                42.0              42.0     41198.0         1642.0   \n",
            "\n",
            "        pallet_count  truck_signin_datetime  load_time  truck_time  \n",
            "191784          28.0           1.562101e+09     1020.0     86397.0  \n",
            "191785          28.0           1.562101e+09     1020.0     86397.0  \n",
            "191786          28.0           1.562101e+09     1020.0     86397.0  \n",
            "191787          28.0           1.562101e+09     1020.0     86397.0  \n",
            "191788          28.0           1.562101e+09     1020.0     86397.0  \n"
          ]
        }
      ],
      "source": [
        "inbound_post_nan.sort_values(\"truck_signin_datetime\", inplace=True)\n",
        "demand_inbound_merge = pd.merge_asof(demand_train, inbound_post_nan, left_on='datetime_local', right_on='truck_signin_datetime', direction='nearest')\n",
        "\n",
        "demand_inbound_merge_numerical = demand_inbound_merge.copy()\n",
        "demand_inbound_merge_numerical['datetime_local'] = demand_inbound_merge_numerical['datetime_local'].apply(lambda x: time.mktime(x.timetuple()))\n",
        "demand_inbound_merge_numerical['truck_signin_datetime'] = demand_inbound_merge_numerical['truck_signin_datetime'].apply(lambda x: time.mktime(x.timetuple()))\n",
        "\n",
        "print(demand_inbound_merge_numerical.tail())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Regression on train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "G8wQBLpyu9Zw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error: 117325.89532074482\n"
          ]
        }
      ],
      "source": [
        "# Split the data into training and test sets\n",
        "X = demand_inbound_merge_numerical.drop('demand_kW', axis=1)\n",
        "y = demand_inbound_merge_numerical['demand_kW']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set up the pipeline\n",
        "pipeline = Pipeline([\n",
        "    # ('imputer', SimpleImputer(strategy='mean')), # Removing gives better performance for Adaboostregressor\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('regressor', AdaBoostRegressor())\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the model using mean squared error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print('Mean Squared Error:', mse)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Merging outbound with demand"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        Unnamed: 0  datetime_local  demand_kW  net_weight  case_quantity   \n",
            "191784      191784    1.628928e+09   2561.692      9595.0          497.0  \\\n",
            "191785      191785    1.628928e+09   2864.648      9595.0          497.0   \n",
            "191786      191786    1.628928e+09   2820.785      9595.0          497.0   \n",
            "191787      191787    1.628928e+09   2817.942      9595.0          497.0   \n",
            "191788      191788    1.628928e+09   2699.152      9595.0          497.0   \n",
            "\n",
            "        pallet_count  truck_signin_datetime  load_time  truck_time  \n",
            "191784           7.0           1.628928e+09     4081.0     71137.0  \n",
            "191785           7.0           1.628928e+09     4081.0     71137.0  \n",
            "191786           7.0           1.628928e+09     4081.0     71137.0  \n",
            "191787           7.0           1.628928e+09     4081.0     71137.0  \n",
            "191788           7.0           1.628928e+09     4081.0     71137.0  \n"
          ]
        }
      ],
      "source": [
        "outbound_post_nan.sort_values(\"truck_signin_datetime\", inplace=True)\n",
        "demand_outbound_merge = pd.merge_asof(demand_train, outbound_post_nan, left_on='datetime_local', right_on='truck_signin_datetime', direction='nearest')\n",
        "\n",
        "demand_outbound_merge_numerical = demand_outbound_merge.copy()\n",
        "demand_outbound_merge_numerical['datetime_local'] = demand_outbound_merge_numerical['datetime_local'].apply(lambda x: time.mktime(x.timetuple()))\n",
        "demand_outbound_merge_numerical['truck_signin_datetime'] = demand_outbound_merge_numerical['truck_signin_datetime'].apply(lambda x: time.mktime(x.timetuple()))\n",
        "\n",
        "print(demand_outbound_merge_numerical.tail())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Regression on train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error: 120481.46790819016\n"
          ]
        }
      ],
      "source": [
        "# Split the data into training and test sets\n",
        "X = demand_outbound_merge_numerical.drop('demand_kW', axis=1)\n",
        "y = demand_outbound_merge_numerical['demand_kW']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set up the pipeline\n",
        "pipeline = Pipeline([\n",
        "    # ('imputer', SimpleImputer(strategy='mean')), # Removing gives better performance for Adaboostregressor\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('regressor', AdaBoostRegressor())\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the model using mean squared error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print('Mean Squared Error:', mse)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "a43632599ce3a37c0054abbf953200660aecbe64e6d247a294a3afed41a103e3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
