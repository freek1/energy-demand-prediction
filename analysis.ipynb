{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "e0ark8SXuFPw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "import time\n",
        "\n",
        "weather = pd.read_csv('data/weather.csv')\n",
        "pallet_history = pd.read_csv('data/Pallet_history_Gold_Spike.csv')\n",
        "inbound = pd.read_csv('data/inbound_loads.csv')\n",
        "outbound = pd.read_csv('data/outbound_laods.csv')\n",
        "demand = pd.read_csv('data/demand_kWtrain_val.csv')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocessing the csv files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " #####\n",
            "Inbound: \n",
            " ##### \n",
            "\n",
            "Index(['front_temperature', 'middle_temperature', 'back_temperature',\n",
            "       'net_weight', 'case_quantity', 'pallet_count', 'truck_signin_datetime',\n",
            "       'load_time', 'truck_time'],\n",
            "      dtype='object')\n",
            "With NaN: (56146, 9)\n",
            "Without NaN: (8761, 9)\n",
            "\n",
            " #####\n",
            "Outbound: \n",
            " ##### \n",
            "\n",
            "Index(['net_weight', 'case_quantity', 'pallet_count', 'truck_signin_datetime',\n",
            "       'load_time', 'truck_time'],\n",
            "      dtype='object')\n",
            "With NaN: (112363, 6)\n",
            "Without NaN: (96704, 6)\n",
            "\n",
            " #####\n",
            "Demand:  \n",
            " ##### \n",
            "\n",
            "Full dataset: (365349, 3)\n",
            "Answers known until index:  273987\n",
            "Training set, 70%: (191789, 3)\n",
            "Validation set, 30%: (82197, 3)\n",
            "\n",
            " #####\n",
            "Weather:  \n",
            " ##### \n",
            "\n",
            "   Unnamed: 0  Relative Humidity  Temperature  hour    datetime_america\n",
            "0           0              50.37         53.6    18 2018-12-31 18:00:00\n",
            "1           1              50.37         53.6    18 2018-12-31 18:05:00\n",
            "2           2              50.37         53.6    18 2018-12-31 18:10:00\n",
            "3           3              50.37         53.6    18 2018-12-31 18:15:00\n",
            "4           4              50.37         53.6    18 2018-12-31 18:20:00\n",
            "Index(['Unnamed: 0', 'Relative Humidity', 'Temperature', 'hour',\n",
            "       'datetime_america'],\n",
            "      dtype='object')\n",
            "(328242, 5)\n"
          ]
        }
      ],
      "source": [
        "#################\n",
        "# Preprocess inbound csv:\n",
        "#################\n",
        "print('\\n #####\\nInbound: \\n ##### \\n')\n",
        "inbound_post = inbound[inbound.carrier_code != 'CANCEL']\n",
        "inbound_post = inbound[inbound.carrier_code != '']\n",
        "\n",
        "inbound_post['truck_signin_datetime'] = pd.to_datetime(inbound_post['truck_signin_datetime'])\n",
        "\n",
        "# Compute delta times\n",
        "inbound_load_time = pd.to_datetime(inbound_post['load_finish_datetime']) - pd.to_datetime(inbound_post['load_start_datetime'])\n",
        "inbound_truck_time = pd.to_datetime(inbound_post['truck_signin_datetime']) - pd.to_datetime(inbound_post['signout_datetime'])\n",
        "\n",
        "# Drop unnecessary columns\n",
        "inbound_post = inbound_post.drop(['Unnamed: 0', 'warehouse_order_number', 'customer_code', 'load_reference_number', 'carrier_code', 'weight_uom', 'load_finish_datetime', 'load_start_datetime', 'dock_door_number', 'trailer_number', 'signout_datetime'], axis=1)\n",
        "\n",
        "# Add time deltas\n",
        "inbound_post['load_time'] = inbound_load_time\n",
        "inbound_post['truck_time'] = inbound_truck_time\n",
        "\n",
        "print(inbound_post.columns)\n",
        "\n",
        "inbound_post['load_time'] = inbound_post['load_time'].dt.seconds\n",
        "inbound_post['truck_time'] = inbound_post['truck_time'].dt.seconds\n",
        "\n",
        "print('With NaN:', inbound_post.shape)\n",
        "\n",
        "# Drop rows with >0 NaN values\n",
        "inbound_post_nan = inbound_post.dropna().reset_index(drop=True)\n",
        "\n",
        "print('Without NaN:', inbound_post_nan.shape)\n",
        "\n",
        "#################\n",
        "# Preprocess outbound csv:\n",
        "#################\n",
        "print('\\n #####\\nOutbound: \\n ##### \\n')\n",
        "outbound_post = outbound[outbound.carrier_code != 'CANCEL']\n",
        "outbound_post = outbound[outbound.carrier_code != 'VOID']\n",
        "outbound_post = outbound[outbound.carrier_code != '']\n",
        "\n",
        "outbound_post['truck_signin_datetime'] = pd.to_datetime(outbound_post['truck_signin_datetime'])\n",
        "\n",
        "# Compute delta times\n",
        "outbound_load_time = pd.to_datetime(outbound_post['load_finish_datetime']) - pd.to_datetime(outbound_post['load_start_datetime'])\n",
        "outbound_truck_time = pd.to_datetime(outbound_post['truck_signin_datetime']) - pd.to_datetime(outbound_post['signout_datetime'])\n",
        "\n",
        "# Drop unnecessary columns\n",
        "outbound_post = outbound_post.drop(['Unnamed: 0', 'warehouse_order_number', 'customer_code', 'load_reference_number', 'carrier_code', 'weight_uom', 'load_finish_datetime', 'load_start_datetime', 'dock_door_number', 'trailer_number', 'signout_datetime'], axis=1)\n",
        "\n",
        "# Add time deltas\n",
        "outbound_post['load_time'] = outbound_load_time\n",
        "outbound_post['truck_time'] = outbound_truck_time\n",
        "\n",
        "print(outbound_post.columns)\n",
        "\n",
        "outbound_post['load_time'] = outbound_post['load_time'].dt.seconds\n",
        "outbound_post['truck_time'] = outbound_post['truck_time'].dt.seconds\n",
        "\n",
        "print('With NaN:', outbound_post.shape)\n",
        "\n",
        "# Drop rows with >0 NaN values\n",
        "outbound_post_nan = outbound_post.dropna().reset_index(drop=True)\n",
        "\n",
        "print('Without NaN:', outbound_post_nan.shape)\n",
        "\n",
        "#################\n",
        "# Preprocess demand csv:\n",
        "#################\n",
        "print('\\n #####\\nDemand:  \\n ##### \\n')\n",
        "\n",
        "demand['datetime_local'] = pd.to_datetime(demand['datetime_local'])\n",
        "\n",
        "end_known_idx = demand[demand.demand_kW > 1].index[-1]\n",
        "train_val_split = 0.7 # 70% train, 30% val\n",
        "end_train_idx = int((train_val_split) * end_known_idx)\n",
        "demand_train = demand[0:end_train_idx-1]\n",
        "demand_val = demand[end_train_idx:end_known_idx]\n",
        "\n",
        "print('Full dataset:', demand.shape)\n",
        "print('Answers known until index: ', end_known_idx)\n",
        "print(f'Training set, {int(train_val_split*100)}%:', demand_train.shape)\n",
        "print(f'Validation set, {int(100-train_val_split*100)}%:', demand_val.shape)\n",
        "\n",
        "#################\n",
        "# Preprocess weather csv:\n",
        "#################\n",
        "print('\\n #####\\nWeather:  \\n ##### \\n')\n",
        "\n",
        "weather_post = weather.copy()\n",
        "UTC6 = pd.to_datetime(weather_post['datetime_UTC']) - pd.Timedelta(hours=6)\n",
        "weather_post['datetime_america'] = UTC6\n",
        "weather_post = weather_post.drop('datetime_UTC', axis=1)\n",
        "weather_post = weather_post.drop('datetime', axis=1)\n",
        "\n",
        "print(weather_post.head())\n",
        "print(weather_post.columns)\n",
        "print(weather_post.shape)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Merging inbound with demand"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Unnamed: 0  datetime_local    demand_kW  front_temperature   \n",
            "0           0    1.546287e+09  2064.101392               -4.0  \\\n",
            "1           1    1.546288e+09  1874.002081               -4.0   \n",
            "2           2    1.546289e+09  1988.168511               -4.0   \n",
            "3           3    1.546290e+09  2022.795943               -4.0   \n",
            "4           4    1.546291e+09  1986.981872               -4.0   \n",
            "\n",
            "   middle_temperature  back_temperature  net_weight  case_quantity   \n",
            "0                -4.0              -4.0     45264.0         1476.0  \\\n",
            "1                -4.0              -4.0     45264.0         1476.0   \n",
            "2                -4.0              -4.0     45264.0         1476.0   \n",
            "3                -4.0              -4.0     45264.0         1476.0   \n",
            "4                -4.0              -4.0     45264.0         1476.0   \n",
            "\n",
            "   pallet_count  truck_signin_datetime  load_time  truck_time  \n",
            "0          24.0           1.546264e+09     1140.0     86399.0  \n",
            "1          24.0           1.546264e+09     1140.0     86399.0  \n",
            "2          24.0           1.546264e+09     1140.0     86399.0  \n",
            "3          24.0           1.546264e+09     1140.0     86399.0  \n",
            "4          24.0           1.546264e+09     1140.0     86399.0  \n"
          ]
        }
      ],
      "source": [
        "inbound_post_nan.sort_values(\"truck_signin_datetime\", inplace=True)\n",
        "demand_inbound_merge = pd.merge_asof(demand_train, inbound_post_nan, left_on='datetime_local', right_on='truck_signin_datetime', direction='nearest')\n",
        "\n",
        "demand_inbound_merge_numerical = demand_inbound_merge.copy()\n",
        "demand_inbound_merge_numerical['datetime_local'] = demand_inbound_merge_numerical['datetime_local'].apply(lambda x: time.mktime(x.timetuple()))\n",
        "demand_inbound_merge_numerical['truck_signin_datetime'] = demand_inbound_merge_numerical['truck_signin_datetime'].apply(lambda x: time.mktime(x.timetuple()))\n",
        "\n",
        "print(demand_inbound_merge_numerical.head())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Regression on train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "G8wQBLpyu9Zw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error: 135929.35941719066\n"
          ]
        }
      ],
      "source": [
        "# Split the data into training and test sets\n",
        "X = demand_inbound_merge_numerical.drop('demand_kW', axis=1)\n",
        "y = demand_inbound_merge_numerical['demand_kW']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set up the pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('regressor', AdaBoostRegressor())\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the model using mean squared error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print('Mean Squared Error:', mse)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Merging outbound with inbound-demand"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        Unnamed: 0  datetime_local  demand_kW  front_temperature   \n",
            "191784      191784    1.628928e+09   2561.692               41.0  \\\n",
            "191785      191785    1.628928e+09   2864.648               41.0   \n",
            "191786      191786    1.628928e+09   2820.785               41.0   \n",
            "191787      191787    1.628928e+09   2817.942               41.0   \n",
            "191788      191788    1.628928e+09   2699.152               41.0   \n",
            "\n",
            "        middle_temperature  back_temperature  net_weight_inbound   \n",
            "191784                42.0              42.0             41198.0  \\\n",
            "191785                42.0              42.0             41198.0   \n",
            "191786                42.0              42.0             41198.0   \n",
            "191787                42.0              42.0             41198.0   \n",
            "191788                42.0              42.0             41198.0   \n",
            "\n",
            "        case_quantity_inbound  pallet_count_inbound   \n",
            "191784                 1642.0                  28.0  \\\n",
            "191785                 1642.0                  28.0   \n",
            "191786                 1642.0                  28.0   \n",
            "191787                 1642.0                  28.0   \n",
            "191788                 1642.0                  28.0   \n",
            "\n",
            "        truck_signin_datetime_inbound  load_time_inbound  truck_time_inbound   \n",
            "191784                   1.562101e+09             1020.0             86397.0  \\\n",
            "191785                   1.562101e+09             1020.0             86397.0   \n",
            "191786                   1.562101e+09             1020.0             86397.0   \n",
            "191787                   1.562101e+09             1020.0             86397.0   \n",
            "191788                   1.562101e+09             1020.0             86397.0   \n",
            "\n",
            "        net_weight_outbound  case_quantity_outbound  pallet_count_outbound   \n",
            "191784               9595.0                   497.0                    7.0  \\\n",
            "191785               9595.0                   497.0                    7.0   \n",
            "191786               9595.0                   497.0                    7.0   \n",
            "191787               9595.0                   497.0                    7.0   \n",
            "191788               9595.0                   497.0                    7.0   \n",
            "\n",
            "        truck_signin_datetime_outbound  load_time_outbound   \n",
            "191784                    1.628928e+09              4081.0  \\\n",
            "191785                    1.628928e+09              4081.0   \n",
            "191786                    1.628928e+09              4081.0   \n",
            "191787                    1.628928e+09              4081.0   \n",
            "191788                    1.628928e+09              4081.0   \n",
            "\n",
            "        truck_time_outbound  \n",
            "191784              71137.0  \n",
            "191785              71137.0  \n",
            "191786              71137.0  \n",
            "191787              71137.0  \n",
            "191788              71137.0  \n"
          ]
        }
      ],
      "source": [
        "outbound_post_nan.sort_values(\"truck_signin_datetime\", inplace=True)\n",
        "outbound_merge = pd.merge_asof(demand_inbound_merge, outbound_post_nan, left_on='datetime_local', right_on='truck_signin_datetime', direction='nearest', suffixes=('_inbound', '_outbound'))\n",
        "\n",
        "outbound_merge_numerical = outbound_merge.copy()\n",
        "outbound_merge_numerical['datetime_local'] = outbound_merge_numerical['datetime_local'].apply(lambda x: time.mktime(x.timetuple()))\n",
        "outbound_merge_numerical['truck_signin_datetime_inbound'] = outbound_merge_numerical['truck_signin_datetime_inbound'].apply(lambda x: time.mktime(x.timetuple()))\n",
        "outbound_merge_numerical['truck_signin_datetime_outbound'] = outbound_merge_numerical['truck_signin_datetime_outbound'].apply(lambda x: time.mktime(x.timetuple()))\n",
        "\n",
        "print(outbound_merge_numerical.tail())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Regression on train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error: 127872.91450295525\n"
          ]
        }
      ],
      "source": [
        "# Split the data into training and test sets\n",
        "X = outbound_merge_numerical.drop('demand_kW', axis=1)\n",
        "y = outbound_merge_numerical['demand_kW']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set up the pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('regressor', AdaBoostRegressor())\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the model using mean squared error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print('Mean Squared Error:', mse)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Merging with weather"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        Unnamed: 0_x  datetime_local  demand_kW  front_temperature   \n",
            "191784        191784    1.628928e+09   2561.692               41.0  \\\n",
            "191785        191785    1.628928e+09   2864.648               41.0   \n",
            "191786        191786    1.628928e+09   2820.785               41.0   \n",
            "191787        191787    1.628928e+09   2817.942               41.0   \n",
            "191788        191788    1.628928e+09   2699.152               41.0   \n",
            "\n",
            "        middle_temperature  back_temperature  net_weight_inbound   \n",
            "191784                42.0              42.0             41198.0  \\\n",
            "191785                42.0              42.0             41198.0   \n",
            "191786                42.0              42.0             41198.0   \n",
            "191787                42.0              42.0             41198.0   \n",
            "191788                42.0              42.0             41198.0   \n",
            "\n",
            "        case_quantity_inbound  pallet_count_inbound   \n",
            "191784                 1642.0                  28.0  \\\n",
            "191785                 1642.0                  28.0   \n",
            "191786                 1642.0                  28.0   \n",
            "191787                 1642.0                  28.0   \n",
            "191788                 1642.0                  28.0   \n",
            "\n",
            "        truck_signin_datetime_inbound  ...  case_quantity_outbound   \n",
            "191784                   1.562101e+09  ...                   497.0  \\\n",
            "191785                   1.562101e+09  ...                   497.0   \n",
            "191786                   1.562101e+09  ...                   497.0   \n",
            "191787                   1.562101e+09  ...                   497.0   \n",
            "191788                   1.562101e+09  ...                   497.0   \n",
            "\n",
            "        pallet_count_outbound  truck_signin_datetime_outbound   \n",
            "191784                    7.0                    1.628928e+09  \\\n",
            "191785                    7.0                    1.628928e+09   \n",
            "191786                    7.0                    1.628928e+09   \n",
            "191787                    7.0                    1.628928e+09   \n",
            "191788                    7.0                    1.628928e+09   \n",
            "\n",
            "        load_time_outbound  truck_time_outbound  Unnamed: 0_y   \n",
            "191784              4081.0              71137.0        285808  \\\n",
            "191785              4081.0              71137.0        285809   \n",
            "191786              4081.0              71137.0        285809   \n",
            "191787              4081.0              71137.0        285809   \n",
            "191788              4081.0              71137.0        285809   \n",
            "\n",
            "        Relative Humidity  Temperature  hour  datetime_america  \n",
            "191784              70.17         84.2    11      1.628928e+09  \n",
            "191785              70.17         84.2    11      1.628928e+09  \n",
            "191786              70.17         84.2    11      1.628928e+09  \n",
            "191787              70.17         84.2    11      1.628928e+09  \n",
            "191788              70.17         84.2    11      1.628928e+09  \n",
            "\n",
            "[5 rows x 23 columns]\n"
          ]
        }
      ],
      "source": [
        "weather_post.sort_values(\"datetime_america\", inplace=True)\n",
        "weather_merge = pd.merge_asof(outbound_merge, weather_post, left_on='datetime_local', right_on='datetime_america', direction='nearest')\n",
        "\n",
        "weather_merge_numerical = weather_merge.copy()\n",
        "weather_merge_numerical['datetime_local'] = weather_merge_numerical['datetime_local'].apply(lambda x: time.mktime(x.timetuple()))\n",
        "weather_merge_numerical['truck_signin_datetime_inbound'] = weather_merge_numerical['truck_signin_datetime_inbound'].apply(lambda x: time.mktime(x.timetuple()))\n",
        "weather_merge_numerical['truck_signin_datetime_outbound'] = weather_merge_numerical['truck_signin_datetime_outbound'].apply(lambda x: time.mktime(x.timetuple()))\n",
        "weather_merge_numerical['datetime_america'] = weather_merge_numerical['datetime_america'].apply(lambda x: time.mktime(x.timetuple()))\n",
        "\n",
        "print(weather_merge_numerical.tail())\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Regression on train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error: 100660.65319395604\n"
          ]
        }
      ],
      "source": [
        "# Split the data into training and test sets\n",
        "X = weather_merge_numerical.drop('demand_kW', axis=1)\n",
        "y = weather_merge_numerical['demand_kW']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set up the pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean')), # Needed again for NaN values\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('regressor', AdaBoostRegressor())\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the model using mean squared error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print('Mean Squared Error:', mse)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "a43632599ce3a37c0054abbf953200660aecbe64e6d247a294a3afed41a103e3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
