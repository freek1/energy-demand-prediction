{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import svm, ensemble\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "weather = pd.read_csv('data/weather.csv')\n",
    "pallet_history = pd.read_csv('data/Pallet_history_Gold_Spike.csv')\n",
    "inbound = pd.read_csv('data/inbound_loads.csv')\n",
    "outbound = pd.read_csv('data/outbound_laods.csv')\n",
    "demand = pd.read_csv('data/demand_kWtrain_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " #####\n",
      "Inbound: \n",
      " ##### \n",
      "\n",
      "Index(['front_temperature', 'middle_temperature', 'back_temperature',\n",
      "       'net_weight', 'case_quantity', 'pallet_count', 'truck_signin_datetime',\n",
      "       'load_time', 'truck_time'],\n",
      "      dtype='object')\n",
      "With NaN: (56146, 9)\n",
      "Without NaN: (8761, 9)\n",
      "\n",
      " #####\n",
      "Outbound: \n",
      " ##### \n",
      "\n",
      "Index(['net_weight', 'case_quantity', 'pallet_count', 'truck_signin_datetime',\n",
      "       'load_time', 'truck_time'],\n",
      "      dtype='object')\n",
      "With NaN: (112363, 6)\n",
      "Without NaN: (96704, 6)\n",
      "\n",
      " #####\n",
      "Demand:  \n",
      " ##### \n",
      "\n",
      "Full dataset: (365349, 3)\n",
      "Answers known until index:  273987\n",
      "Training set, 70%: (191790, 3)\n",
      "Validation set, 30%: (82198, 3)\n",
      "Test set (91359, 3)\n",
      "\n",
      " #####\n",
      "Weather:  \n",
      " ##### \n",
      "\n",
      "   Relative Humidity  Temperature    datetime_america\n",
      "0              50.37         53.6 2018-12-31 18:00:00\n",
      "1              50.37         53.6 2018-12-31 18:05:00\n",
      "2              50.37         53.6 2018-12-31 18:10:00\n",
      "3              50.37         53.6 2018-12-31 18:15:00\n",
      "4              50.37         53.6 2018-12-31 18:20:00\n",
      "Index(['Relative Humidity', 'Temperature', 'datetime_america'], dtype='object')\n",
      "(328242, 3)\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "# Preprocess inbound csv:\n",
    "#################\n",
    "print('\\n #####\\nInbound: \\n ##### \\n')\n",
    "inbound_post = inbound[inbound.carrier_code != 'CANCEL']\n",
    "inbound_post = inbound[inbound.carrier_code != '']\n",
    "\n",
    "inbound_post['truck_signin_datetime'] = pd.to_datetime(inbound_post['truck_signin_datetime'])\n",
    "\n",
    "# Compute delta times\n",
    "inbound_load_time = pd.to_datetime(inbound_post['load_finish_datetime']) - pd.to_datetime(inbound_post['load_start_datetime'])\n",
    "inbound_truck_time = pd.to_datetime(inbound_post['truck_signin_datetime']) - pd.to_datetime(inbound_post['signout_datetime'])\n",
    "\n",
    "# Drop unnecessary columns\n",
    "inbound_post = inbound_post.drop(['Unnamed: 0', 'warehouse_order_number', 'customer_code', 'load_reference_number', 'carrier_code', 'weight_uom', 'load_finish_datetime', 'load_start_datetime', 'dock_door_number', 'trailer_number', 'signout_datetime'], axis=1)\n",
    "\n",
    "# Add time deltas\n",
    "inbound_post['load_time'] = inbound_load_time\n",
    "inbound_post['truck_time'] = inbound_truck_time\n",
    "\n",
    "print(inbound_post.columns)\n",
    "\n",
    "inbound_post['load_time'] = inbound_post['load_time'].dt.seconds\n",
    "inbound_post['truck_time'] = inbound_post['truck_time'].dt.seconds\n",
    "\n",
    "print('With NaN:', inbound_post.shape)\n",
    "\n",
    "# Drop rows with >0 NaN values\n",
    "inbound_post_nan = inbound_post.dropna().reset_index(drop=True)\n",
    "\n",
    "print('Without NaN:', inbound_post_nan.shape)\n",
    "\n",
    "#################\n",
    "# Preprocess outbound csv:\n",
    "#################\n",
    "print('\\n #####\\nOutbound: \\n ##### \\n')\n",
    "outbound_post = outbound[outbound.carrier_code != 'CANCEL']\n",
    "outbound_post = outbound[outbound.carrier_code != 'VOID']\n",
    "outbound_post = outbound[outbound.carrier_code != '']\n",
    "\n",
    "outbound_post['truck_signin_datetime'] = pd.to_datetime(outbound_post['truck_signin_datetime'])\n",
    "\n",
    "# Compute delta times\n",
    "outbound_load_time = pd.to_datetime(outbound_post['load_finish_datetime']) - pd.to_datetime(outbound_post['load_start_datetime'])\n",
    "outbound_truck_time = pd.to_datetime(outbound_post['truck_signin_datetime']) - pd.to_datetime(outbound_post['signout_datetime'])\n",
    "\n",
    "# Drop unnecessary columns\n",
    "outbound_post = outbound_post.drop(['Unnamed: 0', 'warehouse_order_number', 'customer_code', 'load_reference_number', 'carrier_code', 'weight_uom', 'load_finish_datetime', 'load_start_datetime', 'dock_door_number', 'trailer_number', 'signout_datetime'], axis=1)\n",
    "\n",
    "# Add time deltas\n",
    "outbound_post['load_time'] = outbound_load_time\n",
    "outbound_post['truck_time'] = outbound_truck_time\n",
    "\n",
    "print(outbound_post.columns)\n",
    "\n",
    "outbound_post['load_time'] = outbound_post['load_time'].dt.seconds\n",
    "outbound_post['truck_time'] = outbound_post['truck_time'].dt.seconds\n",
    "\n",
    "print('With NaN:', outbound_post.shape)\n",
    "\n",
    "# Drop rows with >0 NaN values\n",
    "outbound_post_nan = outbound_post.dropna().reset_index(drop=True)\n",
    "\n",
    "print('Without NaN:', outbound_post_nan.shape)\n",
    "\n",
    "#################\n",
    "# Preprocess demand csv:\n",
    "#################\n",
    "print('\\n #####\\nDemand:  \\n ##### \\n')\n",
    "\n",
    "demand['datetime_local'] = pd.to_datetime(demand['datetime_local'])\n",
    "\n",
    "end_known_idx = demand[demand.demand_kW > 1].index[-1]\n",
    "train_val_split = 0.7 # 70% train, 30% val\n",
    "end_train_idx = int((train_val_split) * end_known_idx)\n",
    "demand_train = demand.loc[0:end_train_idx-1]\n",
    "demand_val = demand.loc[end_train_idx:end_known_idx]\n",
    "demand_test = demand.iloc[end_known_idx+1:-2]\n",
    "\n",
    "print('Full dataset:', demand.shape)\n",
    "print('Answers known until index: ', end_known_idx)\n",
    "print(f'Training set, {int(train_val_split*100)}%:', demand_train.shape)\n",
    "print(f'Validation set, {int(100-train_val_split*100)}%:', demand_val.shape)\n",
    "print('Test set', demand_test.shape)\n",
    "\n",
    "#################\n",
    "# Preprocess weather csv:\n",
    "#################\n",
    "print('\\n #####\\nWeather:  \\n ##### \\n')\n",
    "\n",
    "weather_post = weather.copy()\n",
    "UTC6 = pd.to_datetime(weather_post['datetime_UTC']) - pd.Timedelta(hours=6)\n",
    "weather_post['datetime_america'] = UTC6\n",
    "weather_post = weather_post.drop('datetime_UTC', axis=1)\n",
    "weather_post = weather_post.drop(['datetime', 'hour', 'Unnamed: 0'], axis=1)\n",
    "\n",
    "print(weather_post.head())\n",
    "print(weather_post.columns)\n",
    "print(weather_post.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weather (328242, 3) \n",
      "\n",
      "demand_train (191790, 3)\n",
      "demand_val (82198, 3)\n",
      "demand_test (91359, 3) \n",
      "\n",
      "train merged (191790, 4)\n",
      "val merged (82198, 4)\n",
      "test merged (91359, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime_local</th>\n",
       "      <th>demand_kW</th>\n",
       "      <th>Relative Humidity</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-31 21:15:00</td>\n",
       "      <td>2064.101392</td>\n",
       "      <td>61.27</td>\n",
       "      <td>46.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-31 21:30:00</td>\n",
       "      <td>1874.002081</td>\n",
       "      <td>61.27</td>\n",
       "      <td>46.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-31 21:45:00</td>\n",
       "      <td>1988.168511</td>\n",
       "      <td>65.60</td>\n",
       "      <td>44.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-31 22:00:00</td>\n",
       "      <td>2022.795943</td>\n",
       "      <td>65.60</td>\n",
       "      <td>44.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-31 22:15:00</td>\n",
       "      <td>1986.981872</td>\n",
       "      <td>65.60</td>\n",
       "      <td>44.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       datetime_local    demand_kW  Relative Humidity  Temperature\n",
       "0 2018-12-31 21:15:00  2064.101392              61.27         46.4\n",
       "1 2018-12-31 21:30:00  1874.002081              61.27         46.4\n",
       "2 2018-12-31 21:45:00  1988.168511              65.60         44.6\n",
       "3 2018-12-31 22:00:00  2022.795943              65.60         44.6\n",
       "4 2018-12-31 22:15:00  1986.981872              65.60         44.6"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine weather and demand data to train, val, and test sets\n",
    "\n",
    "weather_post.sort_values(\"datetime_america\", inplace=True)\n",
    "demand_test.sort_values(\"datetime_local\", inplace=True)\n",
    "print(\"weather\", weather_post.shape, '\\n')\n",
    "print(\"demand_train\", demand_train.shape)\n",
    "print(\"demand_val\", demand_val.shape)\n",
    "print(\"demand_test\", demand_test.shape, '\\n')\n",
    "demand_weather_train = pd.merge_asof(demand_train, weather_post, left_on='datetime_local', right_on='datetime_america', direction='nearest')\n",
    "demand_weather_val = pd.merge_asof(demand_val, weather_post, left_on='datetime_local', right_on='datetime_america', direction='nearest')\n",
    "demand_weather_test = pd.merge_asof(demand_test, weather_post, left_on='datetime_local', right_on='datetime_america', direction='nearest')\n",
    "\n",
    "# demand_weather_train.set_index('datetime_local', inplace=True)\n",
    "demand_weather_train = demand_weather_train.drop(['Unnamed: 0','datetime_america'], axis=1)\n",
    "# demand_weather_val.set_index('datetime_local', inplace=True)\n",
    "demand_weather_val = demand_weather_val.drop(['Unnamed: 0','datetime_america'], axis=1)\n",
    "# demand_weather_test.set_index('datetime_local', inplace=True)\n",
    "demand_weather_test = demand_weather_test.drop(['Unnamed: 0','datetime_america'], axis=1)\n",
    "\n",
    "print(\"train merged\", demand_weather_train.shape)\n",
    "print(\"val merged\", demand_weather_val.shape)\n",
    "print(\"test merged\", demand_weather_test.shape)\n",
    "\n",
    "demand_weather_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train pre (191790, 4)\n",
      "val pre (82198, 4)\n",
      "test pre (91359, 4) \n",
      "\n",
      "train post (191790, 12)\n",
      "val post (82198, 12)\n",
      "test post (91359, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime_local</th>\n",
       "      <th>demand_kW</th>\n",
       "      <th>Relative Humidity</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>front_temperature</th>\n",
       "      <th>middle_temperature</th>\n",
       "      <th>back_temperature</th>\n",
       "      <th>net_weight</th>\n",
       "      <th>case_quantity</th>\n",
       "      <th>pallet_count</th>\n",
       "      <th>load_time</th>\n",
       "      <th>truck_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-31 21:15:00</td>\n",
       "      <td>2064.101392</td>\n",
       "      <td>61.27</td>\n",
       "      <td>46.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-31 21:30:00</td>\n",
       "      <td>1874.002081</td>\n",
       "      <td>61.27</td>\n",
       "      <td>46.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-31 21:45:00</td>\n",
       "      <td>1988.168511</td>\n",
       "      <td>65.60</td>\n",
       "      <td>44.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-31 22:00:00</td>\n",
       "      <td>2022.795943</td>\n",
       "      <td>65.60</td>\n",
       "      <td>44.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-31 22:15:00</td>\n",
       "      <td>1986.981872</td>\n",
       "      <td>65.60</td>\n",
       "      <td>44.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       datetime_local    demand_kW  Relative Humidity  Temperature  \\\n",
       "0 2018-12-31 21:15:00  2064.101392              61.27         46.4   \n",
       "1 2018-12-31 21:30:00  1874.002081              61.27         46.4   \n",
       "2 2018-12-31 21:45:00  1988.168511              65.60         44.6   \n",
       "3 2018-12-31 22:00:00  2022.795943              65.60         44.6   \n",
       "4 2018-12-31 22:15:00  1986.981872              65.60         44.6   \n",
       "\n",
       "   front_temperature  middle_temperature  back_temperature  net_weight  \\\n",
       "0                NaN                 NaN               NaN         NaN   \n",
       "1                NaN                 NaN               NaN         NaN   \n",
       "2                NaN                 NaN               NaN         NaN   \n",
       "3                NaN                 NaN               NaN         NaN   \n",
       "4                NaN                 NaN               NaN         NaN   \n",
       "\n",
       "   case_quantity  pallet_count  load_time  truck_time  \n",
       "0            NaN           NaN        NaN         NaN  \n",
       "1            NaN           NaN        NaN         NaN  \n",
       "2            NaN           NaN        NaN         NaN  \n",
       "3            NaN           NaN        NaN         NaN  \n",
       "4            NaN           NaN        NaN         NaN  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging inbound with the above demand/weather dataset. Maximum 15 minutes difference in order to merge.\n",
    "# Results in NaN and NaT where > 15 mins difference.\n",
    "inbound_post_nan.sort_values(\"truck_signin_datetime\", inplace=True)\n",
    "print(\"train pre\", demand_weather_train.shape)\n",
    "print(\"val pre\", demand_weather_val.shape)\n",
    "print(\"test pre\", demand_weather_test.shape, '\\n')\n",
    "\n",
    "demand_inbound_merge_train = pd.merge_asof(demand_weather_train, inbound_post_nan, \n",
    "                                     left_on='datetime_local', \n",
    "                                     right_on='truck_signin_datetime', \n",
    "                                     direction='nearest', \n",
    "                                     tolerance=datetime.timedelta(minutes = 15))\n",
    "demand_inbound_merge_val = pd.merge_asof(demand_weather_val, inbound_post_nan, \n",
    "                                     left_on='datetime_local', \n",
    "                                     right_on='truck_signin_datetime', \n",
    "                                     direction='nearest', \n",
    "                                     tolerance=datetime.timedelta(minutes = 15))\n",
    "demand_inbound_merge_test = pd.merge_asof(demand_weather_test, inbound_post_nan, \n",
    "                                     left_on='datetime_local', \n",
    "                                     right_on='truck_signin_datetime', \n",
    "                                     direction='nearest', \n",
    "                                     tolerance=datetime.timedelta(minutes = 15))\n",
    "\n",
    "demand_inbound_merge_train = demand_inbound_merge_train.drop(['truck_signin_datetime'], axis=1)\n",
    "# demand_inbound_merge_train.set_index('datetime_local', inplace=True)\n",
    "demand_inbound_merge_val = demand_inbound_merge_val.drop(['truck_signin_datetime'], axis=1)\n",
    "# demand_inbound_merge_val.set_index('datetime_local', inplace=True)\n",
    "demand_inbound_merge_test = demand_inbound_merge_test.drop(['truck_signin_datetime'], axis=1)\n",
    "# demand_inbound_merge_test.set_index('datetime_local', inplace=True)\n",
    "\n",
    "print(\"train post\", demand_inbound_merge_train.shape)\n",
    "print(\"val post\", demand_inbound_merge_val.shape)\n",
    "print(\"test post\", demand_inbound_merge_test.shape)\n",
    "\n",
    "demand_inbound_merge_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train pre (191790, 12)\n",
      "val pre (82198, 12)\n",
      "test pre (91359, 12) \n",
      "\n",
      "train post (191790, 16)\n",
      "val post (82198, 16)\n",
      "test post (91359, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_kW</th>\n",
       "      <th>Relative Humidity</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>front_temperature</th>\n",
       "      <th>middle_temperature</th>\n",
       "      <th>back_temperature</th>\n",
       "      <th>net_weight_in</th>\n",
       "      <th>case_quantity_in</th>\n",
       "      <th>pallet_count_in</th>\n",
       "      <th>load_time_in</th>\n",
       "      <th>truck_time_in</th>\n",
       "      <th>net_weight_out</th>\n",
       "      <th>case_quantity_out</th>\n",
       "      <th>pallet_count_out</th>\n",
       "      <th>load_time_out</th>\n",
       "      <th>truck_time_out</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime_local</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>2064.101392</td>\n",
       "      <td>61.27</td>\n",
       "      <td>46.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>1874.002081</td>\n",
       "      <td>61.27</td>\n",
       "      <td>46.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30.0</th>\n",
       "      <td>1988.168511</td>\n",
       "      <td>65.60</td>\n",
       "      <td>44.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45.0</th>\n",
       "      <td>2022.795943</td>\n",
       "      <td>65.60</td>\n",
       "      <td>44.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60.0</th>\n",
       "      <td>1986.981872</td>\n",
       "      <td>65.60</td>\n",
       "      <td>44.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  demand_kW  Relative Humidity  Temperature  \\\n",
       "datetime_local                                                \n",
       "0.0             2064.101392              61.27         46.4   \n",
       "15.0            1874.002081              61.27         46.4   \n",
       "30.0            1988.168511              65.60         44.6   \n",
       "45.0            2022.795943              65.60         44.6   \n",
       "60.0            1986.981872              65.60         44.6   \n",
       "\n",
       "                front_temperature  middle_temperature  back_temperature  \\\n",
       "datetime_local                                                            \n",
       "0.0                           NaN                 NaN               NaN   \n",
       "15.0                          NaN                 NaN               NaN   \n",
       "30.0                          NaN                 NaN               NaN   \n",
       "45.0                          NaN                 NaN               NaN   \n",
       "60.0                          NaN                 NaN               NaN   \n",
       "\n",
       "                net_weight_in  case_quantity_in  pallet_count_in  \\\n",
       "datetime_local                                                     \n",
       "0.0                       NaN               NaN              NaN   \n",
       "15.0                      NaN               NaN              NaN   \n",
       "30.0                      NaN               NaN              NaN   \n",
       "45.0                      NaN               NaN              NaN   \n",
       "60.0                      NaN               NaN              NaN   \n",
       "\n",
       "                load_time_in  truck_time_in  net_weight_out  \\\n",
       "datetime_local                                                \n",
       "0.0                      NaN            NaN             NaN   \n",
       "15.0                     NaN            NaN             NaN   \n",
       "30.0                     NaN            NaN             NaN   \n",
       "45.0                     NaN            NaN             NaN   \n",
       "60.0                     NaN            NaN             NaN   \n",
       "\n",
       "                case_quantity_out  pallet_count_out  load_time_out  \\\n",
       "datetime_local                                                       \n",
       "0.0                           NaN               NaN            NaN   \n",
       "15.0                          NaN               NaN            NaN   \n",
       "30.0                          NaN               NaN            NaN   \n",
       "45.0                          NaN               NaN            NaN   \n",
       "60.0                          NaN               NaN            NaN   \n",
       "\n",
       "                truck_time_out  \n",
       "datetime_local                  \n",
       "0.0                        NaN  \n",
       "15.0                       NaN  \n",
       "30.0                       NaN  \n",
       "45.0                       NaN  \n",
       "60.0                       NaN  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging outbound with the above demand/weather/inbound dataset. Maximum 15 minutes difference in order to merge.\n",
    "# Results in NaN and NaT where > 15 mins difference.\n",
    "outbound_post_nan.sort_values(\"truck_signin_datetime\", inplace=True)\n",
    "print(\"train pre\", demand_inbound_merge_train.shape)\n",
    "print(\"val pre\", demand_inbound_merge_val.shape)\n",
    "print(\"test pre\", demand_inbound_merge_test.shape, '\\n')\n",
    "\n",
    "demand_inbound_merge_train = pd.merge_asof(demand_inbound_merge_train, outbound_post_nan, \n",
    "                                     left_on='datetime_local', \n",
    "                                     right_on='truck_signin_datetime', \n",
    "                                     direction='nearest', \n",
    "                                     suffixes=('_in', '_out'),\n",
    "                                     tolerance=datetime.timedelta(minutes = 15))\n",
    "demand_inbound_merge_val = pd.merge_asof(demand_inbound_merge_val, outbound_post_nan, \n",
    "                                     left_on='datetime_local', \n",
    "                                     right_on='truck_signin_datetime', \n",
    "                                     direction='nearest', \n",
    "                                     suffixes=('_in', '_out'),\n",
    "                                     tolerance=datetime.timedelta(minutes = 15))\n",
    "demand_inbound_merge_test = pd.merge_asof(demand_inbound_merge_test, outbound_post_nan, \n",
    "                                     left_on='datetime_local', \n",
    "                                     right_on='truck_signin_datetime', \n",
    "                                     direction='nearest', \n",
    "                                     suffixes=('_in', '_out'),\n",
    "                                     tolerance=datetime.timedelta(minutes = 15))\n",
    "\n",
    "demand_inbound_merge_train = demand_inbound_merge_train.drop(['truck_signin_datetime'], axis=1)\n",
    "demand_inbound_merge_train.set_index('datetime_local', inplace=True)\n",
    "demand_inbound_merge_val = demand_inbound_merge_val.drop(['truck_signin_datetime'], axis=1)\n",
    "demand_inbound_merge_val.set_index('datetime_local', inplace=True)\n",
    "demand_inbound_merge_test = demand_inbound_merge_test.drop(['truck_signin_datetime'], axis=1)\n",
    "demand_inbound_merge_test.set_index('datetime_local', inplace=True)\n",
    "\n",
    "demand_inbound_merge_train.index = (demand_inbound_merge_train.index - demand_inbound_merge_train.index[0]).seconds/60\n",
    "demand_inbound_merge_val.index = (demand_inbound_merge_val.index - demand_inbound_merge_val.index[0]).seconds/60\n",
    "demand_inbound_merge_test.index = (demand_inbound_merge_test.index - demand_inbound_merge_test.index[0]).seconds/60\n",
    "\n",
    "print(\"train post\", demand_inbound_merge_train.shape)\n",
    "print(\"val post\", demand_inbound_merge_val.shape)\n",
    "print(\"test post\", demand_inbound_merge_test.shape)\n",
    "\n",
    "demand_inbound_merge_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have three large dataframes with NaNs where the merges didnt match. Three dataframes: train, val, and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (191790, 16)\n",
      "val: (82198, 16)\n",
      "test: (91359, 16)\n"
     ]
    }
   ],
   "source": [
    "train = demand_inbound_merge_train\n",
    "val = demand_inbound_merge_val\n",
    "test = demand_inbound_merge_test\n",
    "\n",
    "print('train:',train.shape)\n",
    "print('val:',val.shape)\n",
    "print('test:',test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 7 features, but GradientBoostingRegressor is expecting 15 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\freek\\OneDrive\\Documenten\\.Universiteit\\M1\\S2\\AML\\energy-demand-prediction\\weather_only.ipynb Cell 8\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/freek/OneDrive/Documenten/.Universiteit/M1/S2/AML/energy-demand-prediction/weather_only.ipynb#X10sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Predict on the test data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/freek/OneDrive/Documenten/.Universiteit/M1/S2/AML/energy-demand-prediction/weather_only.ipynb#X10sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m test_score \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((params[\u001b[39m\"\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m\"\u001b[39m],), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/freek/OneDrive/Documenten/.Universiteit/M1/S2/AML/energy-demand-prediction/weather_only.ipynb#X10sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, y_pred \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(pipeline\u001b[39m.\u001b[39mstaged_predict(X_val)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/freek/OneDrive/Documenten/.Universiteit/M1/S2/AML/energy-demand-prediction/weather_only.ipynb#X10sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     test_score[i] \u001b[39m=\u001b[39m mean_squared_error(y_val, y_pred)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/freek/OneDrive/Documenten/.Universiteit/M1/S2/AML/energy-demand-prediction/weather_only.ipynb#X10sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39mlist\u001b[39m(pipeline\u001b[39m.\u001b[39mstaged_predict(X_val)))[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\freek\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1822\u001b[0m, in \u001b[0;36mGradientBoostingRegressor.staged_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1804\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstaged_predict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m   1805\u001b[0m     \u001b[39m\"\"\"Predict regression target at each stage for X.\u001b[39;00m\n\u001b[0;32m   1806\u001b[0m \n\u001b[0;32m   1807\u001b[0m \u001b[39m    This method allows monitoring (i.e. determine error on testing set)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1820\u001b[0m \u001b[39m        The predicted value of the input samples.\u001b[39;00m\n\u001b[0;32m   1821\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1822\u001b[0m     \u001b[39mfor\u001b[39;00m raw_predictions \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_staged_raw_predict(X):\n\u001b[0;32m   1823\u001b[0m         \u001b[39myield\u001b[39;00m raw_predictions\u001b[39m.\u001b[39mravel()\n",
      "File \u001b[1;32mc:\\Users\\freek\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:716\u001b[0m, in \u001b[0;36mBaseGradientBoosting._staged_raw_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[39m\"\"\"Compute raw predictions of ``X`` for each iteration.\u001b[39;00m\n\u001b[0;32m    693\u001b[0m \n\u001b[0;32m    694\u001b[0m \u001b[39mThis method allows monitoring (i.e. determine error on testing set)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[39m    ``k == 1``, otherwise ``k==n_classes``.\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[39mif\u001b[39;00m check_input:\n\u001b[1;32m--> 716\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    717\u001b[0m         X, dtype\u001b[39m=\u001b[39;49mDTYPE, order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m    718\u001b[0m     )\n\u001b[0;32m    719\u001b[0m raw_predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raw_predict_init(X)\n\u001b[0;32m    720\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n",
      "File \u001b[1;32mc:\\Users\\freek\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:588\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 588\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    590\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\freek\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:389\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 389\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    390\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    391\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    392\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 7 features, but GradientBoostingRegressor is expecting 15 features as input."
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train = train.drop('demand_kW', axis=1)\n",
    "y_train = pd.DataFrame(np.array(train['demand_kW']).reshape(-1, 1))\n",
    "\n",
    "X_val = val.drop('demand_kW', axis=1)\n",
    "y_val = pd.DataFrame(np.array(val['demand_kW']).reshape(-1, 1))\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "y_train = imputer.fit_transform(y_train).ravel()\n",
    "X_val = imputer.fit_transform(X_val)\n",
    "y_val = imputer.fit_transform(y_val).ravel()\n",
    "\n",
    "# Set up pipeline parameters\n",
    "params = {\n",
    "    \"n_estimators\": 1000,\n",
    "    \"learning_rate\": 1,\n",
    "    \"loss\": \"squared_error\",\n",
    "}\n",
    "\n",
    "pipeline = ensemble.GradientBoostingRegressor(**params),\n",
    "pipeline = pipeline[0]\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "test_score = np.zeros((params[\"n_estimators\"],), dtype=np.float64)\n",
    "for i, y_pred in enumerate(pipeline.staged_predict(X_val)):\n",
    "    test_score[i] = mean_squared_error(y_val, y_pred)\n",
    "\n",
    "y_pred = np.array(list(pipeline.staged_predict(X_val)))[-1]\n",
    "data = {'y_pred': y_pred,\n",
    "        'y_val': y_val}\n",
    "pd.to_csv('output/y_pred_val.csv', index=False, data=data)\n",
    "\n",
    "print('MSE val', mean_squared_error(y_val, y_pred))\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.title(\"Deviance using inbound csv\")\n",
    "plt.plot(\n",
    "    np.arange(params[\"n_estimators\"]) + 1,\n",
    "    pipeline.train_score_,\n",
    "    \"b-\",\n",
    "    label=\"Training Set Deviance\",\n",
    ")\n",
    "plt.plot(\n",
    "    np.arange(params[\"n_estimators\"]) + 1, test_score, \"r-\", label=\"Test Set Deviance\"\n",
    ")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"Boosting Iterations\")\n",
    "plt.ylabel(\"Deviance\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
